{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b4a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce575d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data = pd.read_csv('Bangalore.csv')\n",
    "housing_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "varlist = ['Price','Area','NumBedrooms','Resale','MaintenanceStaff','Gymnasium','SwimmingPool','LandscapedGardens','IndoorGames']\n",
    "data = housing_data[varlist].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad4265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null values\n",
    "print(data.info())\n",
    "\n",
    "# checking for outliers\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a47f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of the features like Gymnaisum should have bool values and the mean should not be more than 1\n",
    "# plotting the to check if scaling is required\n",
    "fig,ax = plt.subplots(1,8, figsize=(25,4), sharey = True)\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter(data[varlist[i+1]],data[varlist[0]])\n",
    "    ax[i].set_xlabel(varlist[i+1])\n",
    "ax[0].set_ylabel('Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6690cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MainenanceStaff, Gymnasium, SwimmingPool, LandscapedGardens and IndoorGames needs to be manipulated\n",
    "MaintenanceStaff = [1 if i>1 else 0 for i in data.MaintenanceStaff]\n",
    "Gymnasium = [1 if i>1 else 0 for i in data.Gymnasium]\n",
    "SwimmingPool = [1 if i>1 else 0 for i in data.SwimmingPool]\n",
    "LandscapedGardens = [1 if i>1 else 0 for i in data.LandscapedGardens]\n",
    "IndoorGames = [1 if i>1 else 0 for i in data.IndoorGames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba25fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the features are scaled except Area and NumBedrooms\n",
    "# performing z-score normalization on Area\n",
    "std_dev = np.std(data.Area)\n",
    "mean = np.mean(data.Area)\n",
    "Area = [(i-mean)/std_dev for i in data.Area]\n",
    "\n",
    "# performing z-score normalization on NumBedrooms\n",
    "std_dev = np.std(data.NumBedrooms)\n",
    "mean = np.mean(data.NumBedrooms)\n",
    "NumBedrooms = [(i-mean)/std_dev for i in data.NumBedrooms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ae5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Price to check if scaling is required\n",
    "plt.scatter(data.Price,list(range(len(data.Price))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed7afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some values are too large\n",
    "# performing z-score normalization on price\n",
    "std_dev = np.std(data.Price)\n",
    "mean = np.mean(data.Price)\n",
    "Price = [(i-std_dev)/mean for i in data.Price]\n",
    "plt.scatter(Price,list(range(len(Price))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf50db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining scaled data into a single dataframe\n",
    "scaled_data = pd.DataFrame()\n",
    "for var in varlist:\n",
    "    if var == 'Resale':\n",
    "        scaled_data[var] = data.Resale\n",
    "    else:\n",
    "        scaled_data[var] = eval(var)\n",
    "\n",
    "fig,ax = plt.subplots(1,8, figsize=(25,4), sharey = True)\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter(scaled_data[varlist[i+1]],scaled_data[varlist[0]])\n",
    "    ax[i].set_xlabel(varlist[i+1])\n",
    "ax[0].set_ylabel('Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training and testing data\n",
    "scaled_data = scaled_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_to_test_ratio = 0.7\n",
    "size = int(train_to_test_ratio * len(scaled_data))\n",
    "\n",
    "data_train = scaled_data[size:]\n",
    "data_test = scaled_data[:size]\n",
    "\n",
    "x_train = data_train[varlist[1:]].values\n",
    "y_train = data_train[varlist[0]].values\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cc681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% derived function\n",
    "def predicted_y(x,w,b):\n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy.ndarray\n",
    "        DESCRIPTION - array of features (x1...xn)\n",
    "    w : numpy.ndarray\n",
    "        DESCRIPTION - array of weights (w1...wn)\n",
    "    b : float\n",
    "        DESCRIPTION - bias\n",
    "    Returns\n",
    "    -------\n",
    "    y : float\n",
    "        DESCRIPTION - predicted y based on x\n",
    "\n",
    "    '''\n",
    "    f = np.dot(w,x) + b\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca607121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "def compute_cost(x_train,y_train,w,b):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : numpy.ndarray\n",
    "        DESCRIPTION - training data features\n",
    "    y_train : numpy.ndarray\n",
    "        DESCRIPTION : training data targets\n",
    "    w : numpy.ndarray\n",
    "        DESCRIPTION - array of weights (w1...wn)\n",
    "    b : float\n",
    "        DESCRIPTION - bias\n",
    "    Returns\n",
    "    -------\n",
    "    y : float\n",
    "        DESCRIPTION - predicted y based on x\n",
    "\n",
    "    '''\n",
    "    SUM = 0\n",
    "    m = x_train.shape[0]\n",
    "    for i in range(m):\n",
    "        x = x_train[i]\n",
    "        y = y_train[i]\n",
    "        \n",
    "        f = predicted_y(x,w,b)\n",
    "        \n",
    "        SUM += (f-y)**2\n",
    "    cost = SUM/(2*m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160eb6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute gradient\n",
    "def compute_gradient(x_train,y_train,w,b):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : numpy.ndarray\n",
    "        DESCRIPTION - training data features\n",
    "    y_train : numpy.ndarray\n",
    "        DESCRIPTION : training data targets\n",
    "    w : numpy.ndarray\n",
    "        DESCRIPTION - array of weights (w1...wn)\n",
    "    b : float\n",
    "        DESCRIPTION - bias\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dj_dw : numpy.ndarray\n",
    "        DESCRIPTION - array of gradient values for all parameters\n",
    "    dj_db : numpy.float64\n",
    "        DESCRIPTION - bias gradient\n",
    "    '''\n",
    "    SUMw = 0\n",
    "    SUMb = 0\n",
    "    \n",
    "    m = x_train.shape[0]\n",
    "    SUMw = np.zeros(8)\n",
    "    SWMb = 0\n",
    "    for i in range(m):\n",
    "        x = x_train[i]\n",
    "        y = y_train[i]\n",
    "\n",
    "        f = predicted_y(x,w,b)\n",
    "        \n",
    "        SUMw += np.array([np.dot((f-y),i) for i in x])\n",
    "        SUMb += f-y\n",
    "\n",
    "    dj_dw = SUMw/m\n",
    "    dj_db = SUMb/m\n",
    "    \n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12572f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient descent\n",
    "def gradient_descent(x_train,y_train,num_iters,alpha,w,b):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : numpy.ndarray\n",
    "        DESCRIPTION - training data features\n",
    "    y_train : numpy.ndarray\n",
    "        DESCRIPTION : training data targets\n",
    "    num_iters : int\n",
    "        DESCRIPTION : number of iterations\n",
    "    alpha : float\n",
    "        DESCRIPTION - learning rate\n",
    "    w : numpy.ndarray\n",
    "        DESCRIPTION - array of weights (w1...wn)\n",
    "    b : float\n",
    "        DESCRIPTION - bias    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    b_history = []\n",
    "    \n",
    "    m = x_train.shape[0]\n",
    "    \n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        dj_dw, dj_db = compute_gradient(x_train,y_train,w,b)\n",
    "        w = w - alpha*dj_dw\n",
    "        b = b - alpha*dj_db\n",
    "        \n",
    "        cost = compute_cost(x_train, y_train,w,b)\n",
    "        J_history.append(cost)\n",
    "        w_history.append(w)\n",
    "        b_history.append(b)\n",
    "        \n",
    "        if i% math.ceil(num_iters/10) == 0:\n",
    "            print(f\"Iteration {i:4}: Cost {J_history[-1]:0.2e} \")\n",
    "                 # f\"dj_dw: {dj_dw}, dj_db: {dj_db: 0.3e}  \",\n",
    "                 # f\"w: {w}, b:{b: 0.5e}\")\n",
    "        # break the loop if the cost has converged i.e. the diference in cost is less than 1e-7\n",
    "        if  i>1000 and  (J_history[-1] - J_history[-2] <= 1e-7):    \n",
    "            print('\\ncost has converged')\n",
    "            break\n",
    "    print('w = {}\\nb = {}'.format(w,b))\n",
    "    return J_history, w_history, b_history #return w and J,w history for graphing\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370b41cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "w = np.random.normal(size=8)\n",
    "b = 0\n",
    "num_iters = 10000\n",
    "alpha = 1e-2\n",
    "\n",
    "# perform gradient descent\n",
    "J_history, w_history, b_history = gradient_descent(x_train, y_train, num_iters, alpha, w, b)\n",
    "toc = time.time()\n",
    "time = (toc-tic)/60\n",
    "print(f'time : {time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c630c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = plt.figure(1)\n",
    "f1.add_subplot(3,1,1)\n",
    "plt.plot(w_history[:][0],label = 'w')\n",
    "plt.legend()\n",
    "f1.add_subplot(3,1,2)\n",
    "plt.plot(b_history,label='b')\n",
    "plt.legend()\n",
    "f1.add_subplot(3,1,3)\n",
    "plt.plot(J_history,label = 'cost')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
